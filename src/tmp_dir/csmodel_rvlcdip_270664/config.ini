[COMMON]
seed = 88
dataset_name = rvlcdip
train_part = 2
filter_no_answer = True
network_type = csmodel
task_type = cspretrain
graph_feature = True
graph_vect_path = /home/ubuntu/python_projects/DocGraph4LM/src/tmp_dir/graphsage_docvqa4g_522066/
batch_size = 2
epochs = 1
lr = 1e-05
patience = 10
dropout = 0.2
max_seq_len = 512
hidden_size = 768
hidden_dim = 100
hidden_dim_1 = 64
hidden_dim_2 = 32
continue_train = False
continue_with_model = tmp_dir/graph_layoutlm_docvqa4lm_orig_69.84
embedding_trainable = True
rvl_cdip = /home/ubuntu/air/vrdu/datasets/rvl_pretrain_datasets/0.hf
funsd_train = ../data/FUNSD/training_data/
funsd_test = ../data/FUNSD/testing_data/
roberta_dir = /home/ubuntu/resources/roberta.base.squad
cord_train = ../data/CORD/train/
cord_test = ../data/CORD/test/
docvqa_dir = /home/ubuntu/air/vrdu/datasets/docvqa/
docvqa_train = /home/ubuntu/air/vrdu/datasets/docvqa/train/
docvqa_test = /home/ubuntu/air/vrdu/datasets/docvqa/test/
docvqa_pickles = /home/ubuntu/air/vrdu/datasets/docvqa/pickles/
config_file = config/lm.ini
device = cuda

